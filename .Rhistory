data_long$channel[disp_inds]="display"
email_inds=grep("email",data_long$channel)
data_long$channel[email_inds]="email"
email_inds=grep("paid",data_long$channel)
data_long$channel[email_inds]="paid"
email_inds=grep("organic",data_long$channel)
data_long$channel[email_inds]="organic"
#combine displays and combine emails by order
data_long=data_long %>% group_by(order_number,channel) %>%
summarise(session_count=sum(session_count),purchaser=first(purchaser))
#recheck channel distribution with corrections
data_long %>% group_by(channel,purchaser) %>%  summarise(count=n()) %>% arrange(desc(count))
data_long %>% group_by(purchaser) %>%  summarise(count=n()) %>% arrange(desc(count))
data_wide=data_long %>%  spread(key=channel,value=session_count)
data_wide
#setting all missings to 0
numeric_inds=sapply(data_wide,is.numeric)
data_wide[,numeric_inds]=apply(data_wide[,numeric_inds],2,function(x){
na_inds=which(is.na(x))
if (length(na_inds)>0){
x[na_inds]=0
} else {
x
}
x
})
#combining orders for total sessions by each channel
data_wide=data_wide %>% group_by(order_number) %>% summarise(purchaser=first(purchaser),affiliates=sum(affiliates),
direct=sum(direct),display=sum(display),email=sum(email),
organic=sum(organic),paid=sum(paid),referral=sum(referral))
#order_number is irrelevant now
data_wide$order_number=NULL
##Sanity checks
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
summary(row_sums)
sd(row_sums)
qplot(row_sums)
#omitting outrageously high session counts
high_inds=which(row_sums> (mean(row_sums)+10*sd(row_sums)))
if (length(high_inds)) data_wide=data_wide[-high_inds,]
data_wide$row_sums=row_sums
data_wide %>% group_by(purchaser) %>% summarise(row_sums=mean(row_sums))
summary(as.vector(data_wide %>% filter(purchaser==0) %>% select(row_sums)))
high_inds
library(tidyr)
library(dplyr)
library(corrplot)
library(glmnet)
library(readr)
library(caret)
source("Ritani_log_analysis_DB_connection.R")
###
#####imorting purchasers
query=paste("
SELECT order_number, name AS channel, state,
max(total) AS revenue, count(*) as session_count
FROM (
SELECT channel_id, clickstream_id, session_id
FROM channel_touchpoints
) ct INNER JOIN (
SELECT id, name, has_attributed_revenue
FROM channels
) ch ON ct.channel_id=ch.id
INNER JOIN (
SELECT id, pre_purchase
FROM sessions
WHERE pre_purchase=1
) se ON ct.session_id=se.id
INNER JOIN (
SELECT id, order_number, total, state
FROM clickstreams
) cl ON ct.clickstream_id=cl.id
GROUP BY order_number, channel
HAVING state LIKE '%shipped%' OR state LIKE '%accepted%' OR state LIKE '%delivered%'
OR state LIKE '%store%' OR state LIKE '%charged%' OR state LIKE '%authorized%'
OR state LIKE '%shipped%'
")
data_long=tbl_df(dbGetQuery(con,query))
#ditching some data
data_long$state=NULL
data_long$revenue=NULL
data_long$revenue=NULL
data_long$purchaser=1
# Importing non-purschasers
non_purchaser_data=tbl_df(read_csv(file=gzfile('non-purchaser-channels.csv.gz'),col_names=FALSE))
non_purchaser_data$X1=NULL
non_purchaser_data$X4=NULL
non_purchaser_data$purchaser=0
non_purchaser_data$session_count=1
non_purchaser_data=non_purchaser_data %>% rename(order_number=X2)
non_purchaser_data=non_purchaser_data %>% rename(channel=X3)
#combine data
data_long=rbind(data_long,non_purchaser_data)
# data_long$purchaser=as.factor(data_long$purchaser)
#cleaning some unneccesary
data_long=data_long[-which(data_long$channel=="unknown"),]
data_long=data_long[-which(data_long$channel=="social"),]
data_long=data_long[-grep("retailer",data_long$channel),]
data_long=data_long[-which(data_long$channel=="tv"),]
data_long=data_long[-which(data_long$channel=="session continuation"),]
#check channel distribution
data_long %>% group_by(channel,purchaser) %>%  summarise(count=n()) %>% arrange(desc(count))
#reassign some channel names
disp_inds=grep("display",data_long$channel)
data_long$channel[disp_inds]="display"
email_inds=grep("email",data_long$channel)
data_long$channel[email_inds]="email"
email_inds=grep("paid",data_long$channel)
data_long$channel[email_inds]="paid"
email_inds=grep("organic",data_long$channel)
data_long$channel[email_inds]="organic"
#combine displays and combine emails by order
data_long=data_long %>% group_by(order_number,channel) %>%
summarise(session_count=sum(session_count),purchaser=first(purchaser))
#recheck channel distribution with corrections
data_long %>% group_by(channel,purchaser) %>%  summarise(count=n()) %>% arrange(desc(count))
data_long %>% group_by(purchaser) %>%  summarise(count=n()) %>% arrange(desc(count))
#need to resample to adjust for class imbalance
#duplicating instead of resampling due to order_number spreading difficulties
channel_levels=levels(as.factor(data_long$channel))
resampled_data_frame=data.frame()
for (channel in channel_levels){
ch_inds=which(data_long$channel==channel)
for (i in 1:round(10000/length(ch_inds))){
temp=data_long[ch_inds,]
temp$order_number=paste0(temp$order_number,i)
resampled_data_frame=rbind(resampled_data_frame,temp)
}
}
#recheck channel distribution with resampling
resampled_data_frame %>% group_by(channel,purchaser) %>%  summarise(count=n()) %>% arrange(desc(count))
# putting data in wide form
# data_wide=resampled_data_frame %>%  spread(key=channel,value=session_count)
#try without bootstrapping
data_wide=data_long %>%  spread(key=channel,value=session_count)
#setting all missings to 0
numeric_inds=sapply(data_wide,is.numeric)
data_wide[,numeric_inds]=apply(data_wide[,numeric_inds],2,function(x){
na_inds=which(is.na(x))
if (length(na_inds)>0){
x[na_inds]=0
} else {
x
}
x
})
data_wide=data_wide %>% group_by(order_number) %>% summarise(purchaser=first(purchaser),affiliates=sum(affiliates),
direct=sum(direct),display=sum(display),email=sum(email),
organic=sum(organic),paid=sum(paid),referral=sum(referral))
#order_number is irrelevant now
data_wide$order_number=NULL
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
summary(row_sums)
sd(row_sums)
qplot(row_sums)
high_inds=which(row_sums> (mean(row_sums)+10*sd(row_sums)))
high_inds
if (length(high_inds)) data_wide=data_wide[-high_inds,]
data_wide$row_sums=row_sums
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
data_wide$row_sums=row_sums
data_wide %>% group_by(purchaser) %>% summarise(row_sums=mean(row_sums))
summary(as.vector(data_wide %>% filter(purchaser==0) %>% select(row_sums)))
summary(as.vector(data_wide %>% filter(purchaser==1) %>% select(row_sums)))
t.test(as.vector(data_wide %>% filter(purchaser==0) %>% select(row_sums))[[1]],
as.vector(data_wide %>% filter(purchaser==1) %>% select(row_sums))[[1]])
ggplot(data_wide %>% filter(row_sums<30))+geom_boxplot(aes(y=row_sums,x=purchaser))
ggplot(data_wide %>% filter(row_sums<30))+geom_density(aes(x=row_sums,color=purchaser))
data_wide$row_sums=NULL
channels_invert=data_wide
channels_invert[,2:8]=data.frame(apply(channels_invert[,2:8],2,function(x){
pos_inds=which(x>0)
x[pos_inds]=1/x[pos_inds]
x
})
)
glm_fit1= glm(purchaser~.+0,
data=data_wide ,binomial)
summary(glm_fit1)
qplot(predict(glm_fit1,newdata= data_wide, type = "response"))
pred=round(predict(glm_fit1,newdata= data_wide, type = "response"))
confusionMatrix(data_wide$purchaser, pred)
summary(glm_fit1)
glm_fit1= lm(purchaser~.+0,
data=data_wide)
summary(glm_fit1)
qplot(predict(glm_fit1,newdata= data_wide, type = "response"))
pred=round(predict(glm_fit1,newdata= data_wide, type = "response"))
confusionMatrix(data_wide$purchaser, pred)
round(coef(glm_fit1)[1:7]/sum(coef(glm_fit1)[1:7]),2)
summary(glm_fit1)
fit1= lm(purchaser~.+0,
data=data_wide)
summary(fit1)
qplot(fitted(fit1))
summary(fitted(fit1))
plot(fit1)
data_wide[30215,]
data_wide=data_wide[-30215,]
fit1= lm(purchaser~.+0,
data=data_wide)
plot(fit1)
data_wide=data_wide[5848,]
data_wide
library(tidyr)
library(dplyr)
library(corrplot)
library(glmnet)
library(readr)
library(caret)
source("Ritani_log_analysis_DB_connection.R")
###
#####imorting purchasers
query=paste("
SELECT order_number, name AS channel, state,
max(total) AS revenue, count(*) as session_count
FROM (
SELECT channel_id, clickstream_id, session_id
FROM channel_touchpoints
) ct INNER JOIN (
SELECT id, name, has_attributed_revenue
FROM channels
) ch ON ct.channel_id=ch.id
INNER JOIN (
SELECT id, pre_purchase
FROM sessions
WHERE pre_purchase=1
) se ON ct.session_id=se.id
INNER JOIN (
SELECT id, order_number, total, state
FROM clickstreams
) cl ON ct.clickstream_id=cl.id
GROUP BY order_number, channel
HAVING state LIKE '%shipped%' OR state LIKE '%accepted%' OR state LIKE '%delivered%'
OR state LIKE '%store%' OR state LIKE '%charged%' OR state LIKE '%authorized%'
OR state LIKE '%shipped%'
")
data_long=tbl_df(dbGetQuery(con,query))
#ditching some data
data_long$state=NULL
data_long$revenue=NULL
data_long$revenue=NULL
data_long$purchaser=1
# Importing non-purschasers
non_purchaser_data=tbl_df(read_csv(file=gzfile('non-purchaser-channels.csv.gz'),col_names=FALSE))
non_purchaser_data$X1=NULL
non_purchaser_data$X4=NULL
non_purchaser_data$purchaser=0
non_purchaser_data$session_count=1
non_purchaser_data=non_purchaser_data %>% rename(order_number=X2)
non_purchaser_data=non_purchaser_data %>% rename(channel=X3)
#combine data
data_long=rbind(data_long,non_purchaser_data)
# data_long$purchaser=as.factor(data_long$purchaser)
#cleaning some unneccesary
data_long=data_long[-which(data_long$channel=="unknown"),]
data_long=data_long[-which(data_long$channel=="social"),]
data_long=data_long[-grep("retailer",data_long$channel),]
data_long=data_long[-which(data_long$channel=="tv"),]
data_long=data_long[-which(data_long$channel=="session continuation"),]
#check channel distribution
data_long %>% group_by(channel,purchaser) %>%  summarise(count=n()) %>% arrange(desc(count))
#reassign some channel names
disp_inds=grep("display",data_long$channel)
data_long$channel[disp_inds]="display"
email_inds=grep("email",data_long$channel)
data_long$channel[email_inds]="email"
email_inds=grep("paid",data_long$channel)
data_long$channel[email_inds]="paid"
email_inds=grep("organic",data_long$channel)
data_long$channel[email_inds]="organic"
#combine displays and combine emails by order
data_long=data_long %>% group_by(order_number,channel) %>%
summarise(session_count=sum(session_count),purchaser=first(purchaser))
#recheck channel distribution with corrections
data_long %>% group_by(channel,purchaser) %>%  summarise(count=n()) %>% arrange(desc(count))
data_long %>% group_by(purchaser) %>%  summarise(count=n()) %>% arrange(desc(count))
#need to resample to adjust for class imbalance
#duplicating instead of resampling due to order_number spreading difficulties
channel_levels=levels(as.factor(data_long$channel))
resampled_data_frame=data.frame()
for (channel in channel_levels){
ch_inds=which(data_long$channel==channel)
for (i in 1:round(10000/length(ch_inds))){
temp=data_long[ch_inds,]
temp$order_number=paste0(temp$order_number,i)
resampled_data_frame=rbind(resampled_data_frame,temp)
}
}
#recheck channel distribution with resampling
resampled_data_frame %>% group_by(channel,purchaser) %>%  summarise(count=n()) %>% arrange(desc(count))
# putting data in wide form
# data_wide=resampled_data_frame %>%  spread(key=channel,value=session_count)
#try without bootstrapping
data_wide=data_long %>%  spread(key=channel,value=session_count)
#setting all missings to 0
numeric_inds=sapply(data_wide,is.numeric)
data_wide[,numeric_inds]=apply(data_wide[,numeric_inds],2,function(x){
na_inds=which(is.na(x))
if (length(na_inds)>0){
x[na_inds]=0
} else {
x
}
x
})
#combining orders for total sessions by each channel
data_wide=data_wide %>% group_by(order_number) %>% summarise(purchaser=first(purchaser),affiliates=sum(affiliates),
direct=sum(direct),display=sum(display),email=sum(email),
organic=sum(organic),paid=sum(paid),referral=sum(referral))
#order_number is irrelevant now
data_wide$order_number=NULL
##Sanity checks
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
summary(row_sums)
sd(row_sums)
qplot(row_sums)
#omitting outrageously high session counts
high_inds=which(row_sums> (mean(row_sums)+10*sd(row_sums)))
if (length(high_inds)) data_wide=data_wide[-high_inds,]
#Visual check to see if number of sessions are related to purchase
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
data_wide$row_sums=row_sums
data_wide %>% group_by(purchaser) %>% summarise(row_sums=mean(row_sums))
summary(as.vector(data_wide %>% filter(purchaser==0) %>% select(row_sums)))
summary(as.vector(data_wide %>% filter(purchaser==1) %>% select(row_sums)))
t.test(as.vector(data_wide %>% filter(purchaser==0) %>% select(row_sums))[[1]],
as.vector(data_wide %>% filter(purchaser==1) %>% select(row_sums))[[1]])
# ggplot(data_wide %>% filter(row_sums<30))+geom_boxplot(aes(y=row_sums,x=purchaser))
# ggplot(data_wide %>% filter(row_sums<30))+geom_density(aes(x=row_sums,color=purchaser))
data_wide$row_sums=NULL
#Invert session counts assuming more sessions are better
channels_invert=data_wide
channels_invert[,2:8]=data.frame(apply(channels_invert[,2:8],2,function(x){
pos_inds=which(x>0)
x[pos_inds]=1/x[pos_inds]
x
})
)
# #Correlation plot of channel sessions
# corrplot(cor(data_wide[,1:8]))
# #correlation plot of channel indicators
# corrplot(cor(channels_invert))
#Checking out various models
#high leverage point
fit1= lm(purchaser~.+0,
data=data_wide)
summary(fit1)
qplot(fitted(fit1))
length(which(fitted(fit1)>1))
fit1= lm(purchaser~.,
data=data_wide)
summary(fit1)
fit1= lm(purchaser~.+0,
data=data_wide)
summary(fit1)
qplot(fitted(fit1))
summary(fit1)
qplot(fitted(fit1))
pred=round(predict(fit1,newdata= data_wide, type = "response"))
confusionMatrix(data_wide$purchaser, pred)
round(coef(fit1)[1:7]/sum(coef(fit1)[1:7]),2)
fit_invert=lm(purchaser~.*.+0,data=channels_invert)
fit_invert=lm(purchaser~.*.+0,data=channels_invert)
summary(fit_invert)
summary(fit_invert)
qplot(predict(fit_invert,newdata= data_wide, type = "response"))
qplot(fitted(fit_invert))
fit1= lm(purchaser~.+0,data=data_wide)
summary(fit1)
qplot(fitted(fit1))
confusionMatrix(data_wide$purchaser, fitted(fit1))
confusionMatrix(as.factor(data_wide$purchaser), as.factor(fitted(fit1)))
levels(as.factor(data_wide$purchaser))
confusionMatrix(data_wide$purchaser, round(fitted(fit1)))
fit_invert=lm(purchaser~.+0,data=channels_invert)
summary(fit_invert)
qplot(fitted(fit_invert))
confusionMatrix(fit_invert$purchaser, round(fitted(fit_invert)))
confusionMatrix(channels_invert$purchaser, round(fitted(fit_invert)))
confusionMatrix(data_wide$purchaser, round(fitted(fit1)))
round(coef(fit1)[1:7]/sum(coef(fit1)[1:7]),2)
round(coef(fit_invert)[1:7]/sum(coef(fit_invert)[1:7]),2)
qplot(fitted(fit1))
qplot(fitted(fit_invert))
summary(fitted(fit_invert))
qplot(fitted(fit1)/max(fitted(fit1)))
qplot(fitted(fit_invert)/max(fitted(fit_invert)))
qplot(fitted(fit1)/max(fitted(fit1)))
summary(fit1)
fit1= lm(purchaser~.+0,data=data_wide)
summary(fit1)
confusionMatrix(data_wide$purchaser, round(fitted(fit1)))
round(coef(fit1)[1:7]/sum(coef(fit1)[1:7]),2)
summary(fit1)
fit1= lm(purchaser~.+0,data=data_wide)
summary(fit1)
summary(fitted(fit1))
qplot(fitted(fit1))
plot(fit1)
data_wide=data_wide[-c(30215,5848),]
fit1= lm(purchaser~.+0,data=data_wide)
summary(fit1)
summary(fitted(fit1))
plot(fit1)
inTrain = createDataPartition(y=data_wide$purchaser, p = .6)[[1]]
training = data_wide[ inTrain,]
testing = data_wide[-inTrain,]
fit1= lm(purchaser~.+0,data=training)
summary(fit1)
summary(fitted(fit1))
qplot(fitted(fit1))
confusionMatrix(training$purchaser, round(fitted(fit1)))
training
confusionMatrix(training$purchaser, round(fitted(fit1)))
confusionMatrix(training$purchaser, predict(fit1,training[,2:8]))
confusionMatrix(training$purchaser, round(predict(fit1,training[,2:8])))
confusionMatrix(training$purchaser, round(fitted(fit1)))
confusionMatrix(training$purchaser, round(predict(fit1,training[,2:8])))
confusionMatrix(training$testing, round(predict(fit1,testing[,2:8])))
summary(round(predict(fit1,testing[,2:8])))
formula(fit1)
x <- model.matrix(formula(fit1),data=training)
x
View(x)
y<- as.matrix(training$purchaser)
fit<-glmnet(x,y, family="gaussian", alpha=0.9, lambda=0.001,intercept=FALSE)
fit
summary(fit)
coefficients(fit)
predictions <- predict(fit, x)
cor(y,predictions)^2
summary(fit1)
summary(predictions)
plot(predictions)
qplot(predictions)
confusionMatrix(training$purchaser, round(predict(fit1,testing[,2:8])))
confusionMatrix(training$purchaser, round(predictions))
x_test <- model.matrix(formula(fit1),data=testing)
y_test<- as.matrix(testing$purchaser)
predictions <- predict(fit, x_test)
confusionMatrix(testing$purchaser, round(predictions))
fit1= lm(purchaser~.+0,data=training)
x <- model.matrix(formula(fit1),data=training)
y<- as.matrix(training$purchaser)
fit<-glmnet(x,y, family="gaussian", alpha=0.9, lambda=0.001,intercept=FALSE)
coefficients(fit)
predictions <- predict(fit, x)
confusionMatrix(training$purchaser, round(predictions))
x_test <- model.matrix(formula(fit1),data=testing)
y_test<- as.matrix(testing$purchaser)
predictions <- predict(fit, x_test)
confusionMatrix(testing$purchaser, round(predictions))
coefficients(fit)
x_test <- model.matrix(formula(fit1),data=data_wide)
y_test<- as.matrix(data_wide$purchaser)
x <- model.matrix(formula(fit1),data=training)
y<- as.matrix(training$purchaser)
fit<-glmnet(x,y, family="gaussian", alpha=0.9, lambda=0.001,intercept=FALSE)
coefficients(fit)
predictions <- predict(fit, x)
confusionMatrix(y, round(predictions))
x_test <- model.matrix(formula(fit1),data=testing)
y_test<- as.matrix(testing$purchaser)
predictions <- predict(fit, x_test)
confusionMatrix(y_test, round(predictions))
x_all <- model.matrix(formula(fit1),data=data_wide)
y_all<- as.matrix(data_wide$purchaser)
predictions <- predict(fit, x_all)
confusionMatrix(y_all, round(predictions))
x <- model.matrix(formula(fit1),data=training)
y<- as.matrix(training$purchaser)
fit<-glmnet(x,y, family="gaussian", alpha=0.1, lambda=0.001,intercept=FALSE)
coefficients(fit)
predictions <- predict(fit, x)
confusionMatrix(y, round(predictions))
x_test <- model.matrix(formula(fit1),data=testing)
y_test<- as.matrix(testing$purchaser)
predictions <- predict(fit, x_test)
confusionMatrix(y_test, round(predictions))
x_all <- model.matrix(formula(fit1),data=data_wide)
y_all<- as.matrix(data_wide$purchaser)
predictions <- predict(fit, x_all)
confusionMatrix(y_all, round(predictions))
x <- model.matrix(formula(fit1),data=training)
y<- as.matrix(training$purchaser)
fit<-glmnet(x,y, family="gaussian", alpha=0.1, lambda=0.001,intercept=FALSE)
coefficients(fit)
predictions <- predict(fit, x)
which(predictions>1)
x <- model.matrix(formula(fit1),data=training)
y<- as.matrix(training$purchaser)
fit<-glmnet(x,y, family="gaussian", alpha=0.1, lambda=0.001,intercept=FALSE)
coefficients(fit)
predictions <- predict(fit, x)
predictions[which(predictions>1)]=1
confusionMatrix(y, round(predictions))
x_test <- model.matrix(formula(fit1),data=testing)
y_test<- as.matrix(testing$purchaser)
predictions <- predict(fit, x_test)
predictions[which(predictions>1)]=1
confusionMatrix(y_test, round(predictions))
x_all <- model.matrix(formula(fit1),data=data_wide)
y_all<- as.matrix(data_wide$purchaser)
predictions <- predict(fit, x_all)
predictions[which(predictions>1)]=1
confusionMatrix(y_all, round(predictions))
coefficients(fit)
as.vector(coefficients(fit))
as.vector(coefficients(fit))[2:8]
as.vector(coefficients(fit))[2:8]/sum(as.vector(coefficients(fit))[2:8])
coefficients(fit)
