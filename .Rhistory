WHERE pre_purchase=1
) se ON ct.session_id=se.id
INNER JOIN (
SELECT id, order_number, total, state
FROM clickstreams
) cl ON ct.clickstream_id=cl.id
GROUP BY order_number, channel
HAVING state LIKE '%shipped%' OR state LIKE '%accepted%' OR state LIKE '%delivered%'
OR state LIKE '%store%' OR state LIKE '%charged%' OR state LIKE '%authorized%'
OR state LIKE '%shipped%'
")
data_long=tbl_df(dbGetQuery(con,query))
#ditching some data
data_long$state=NULL
data_long=data_long[-which(data_long$channel=="unknown"),]
data_long=data_long[-which(data_long$channel=="tv"),]
data_long=data_long[-which(data_long$channel=="session continuation"),]
#check channel distribution
data_long %>% group_by(channel) %>%  summarise(count=n()) %>% arrange(desc(count))
#reassign some channel names
disp_inds=grep("display",data_long$channel)
data_long$channel[disp_inds]="display"
email_inds=grep("email",data_long$channel)
data_long$channel[email_inds]="email"
email_inds=grep("paid",data_long$channel)
data_long$channel[email_inds]="paid"
email_inds=grep("organic",data_long$channel)
data_long$channel[email_inds]="organic"
#combine displays and combine emails by order
data_long=data_long %>% group_by(order_number,channel) %>%
summarise(revenue=max(revenue),session_count=sum(session_count))
#recheck channel distribution with corrections
data_long %>% group_by(channel) %>%  summarise(count=n()) %>% arrange(desc(count))
data_long %>% group_by(order_number) %>%  summarise(count=n()) %>% arrange(desc(count))
#need to resample to adjust for class imbalance
#duplicating instead of resampling due to order_number spreading difficulties
channel_levels=levels(as.factor(data_long$channel))
resampled_data_frame=data.frame()
for (channel in channel_levels){
ch_inds=which(data_long$channel==channel)
for (i in 1:round(30000/length(ch_inds))){
temp=data_long[ch_inds,]
temp$order_number=paste0(temp$order_number,i)
resampled_data_frame=rbind(resampled_data_frame,temp)
}
}
#recheck channel distribution with resampling
resampled_data_frame %>% group_by(channel) %>%  summarise(count=n(),revenue=mean(revenue)) %>% arrange(desc(count))
# putting data in wide form
data_wide=resampled_data_frame %>%   spread(key=channel,value=session_count)
#fix column names
names(data_wide) <- sub(" ", ".", names(data_wide))
#setting all missings to 0
numeric_inds=sapply(data_wide,is.numeric)
data_wide[,numeric_inds]=apply(data_wide[,numeric_inds],2,function(x){
na_inds=which(is.na(x))
if (length(na_inds)>0){
x[na_inds]=0
} else {
x
}
x
})
#combining orders for total sessions by each channel
data_wide=data_wide %>% group_by(order_number) %>% summarise(revenue=mean(revenue),
affiliates=sum(affiliates),direct=sum(direct),display=sum(display),email=sum(email),
organic=sum(organic),paid=sum(paid),referral=sum(referral))
#order_number is irrelevant now
data_wide$order_number=NULL
##Sanity checks
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
summary(row_sums)
sd(row_sums)
qplot(row_sums)
#omitting outrageously high session counts
high_inds=which(row_sums> (mean(row_sums)+10*sd(row_sums)))
if (length(high_inds)) data_wide=data_wide[-high_inds,]
summary(data_wide$revenue)
sd(data_wide$revenue)
qplot(data_wide$revenue)
#omitting outrageously revenue
high_inds=which(data_wide$revenue> (mean(data_wide$revenue)+10*sd(data_wide$revenue)))
if (length(high_inds)) data_wide=data_wide[-high_inds,]
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
#check for implict relationship between total sessions and total revenue
cor(row_sums,data_wide$revenue)
qplot(row_sums,data_wide$revenue)+geom_smooth()+theme_bw()+
xlab("Sessions")+ylab("Purchase Total (Dollars)")
#Dummify for tabulation
channels_dummy=data_wide
channels_dummy[,2:8]=data.frame(apply(channels_dummy[,2:8],2,function(x){
pos_inds=which(x>0)
x[pos_inds]=1
x
})
)
#Invert session counts assuming more sessions are better
channels_invert=data_wide
channels_invert[,2:8]=data.frame(apply(channels_invert[,2:8],2,function(x){
pos_inds=which(x>0)
x[pos_inds]=1/x[pos_inds]
x
})
)
#Correlation plot of channel sessions
corrplot(cor(data_wide[,1:8]))
#correlation plot of channel indicators
corrplot(cor(channels_dummy))
#correlation plot of channel indicators
corrplot(cor(channels_invert))
# #Throwing some models at the wall
# x <- as.matrix(channels_dummy[,2:7])
# y<- as.matrix(channels_dummy[,1])
# fit<-glmnet(x,y, family="gaussian", alpha=0.5, lambda=0.001,intercept=FALSE)
# # summarize the fit
# coefficients(fit)
# # make predictions
# predictions <- predict(fit, x, type="link")
# # summarize accuracy
# R2 <- cor((y - predictions))^2
#
all_model_no_interaction=lm(revenue~.+0,data=data_wide)
summary(all_model_no_interaction)
round(coef(all_model_no_interaction)/sum(coef(all_model_no_interaction)),3)
all_model_no_interaction_dummy=lm(revenue~.+0,data=channels_dummy)
summary(all_model_no_interaction_dummy)
round(coef(all_model_no_interaction_dummy)/sum(coef(all_model_no_interaction_dummy)),3)
all_model_no_interaction_invert=lm(revenue~.+0,data=channels_invert)
summary(all_model_no_interaction_invert)
round(coef(all_model_no_interaction_invert)/sum(coef(all_model_no_interaction_invert)),3)
#Continuing using the dummy indicators- now check for interaction
#The front runner
all_model_dummy=lm(revenue~.*.+0,data=channels_dummy)
summary(all_model_dummy)
stepwise_model=step(all_model_dummy,k=log(nrow(channels_dummy)))
summary(stepwise_model)
anova(stepwise_model,all_model_no_interaction_dummy, test="Chi")
round(coef(stepwise_model)[1:7]/sum(coef(stepwise_model)[1:7]),3)
round(coef(stepwise_model)[1:7]/sum(coef(stepwise_model)[1:7]),2)
corrplot(cor(channels_dummy))
data_long=tbl_df(dbGetQuery(con,query))
#ditching some data
data_long$state=NULL
data_long=data_long[-which(data_long$channel=="unknown"),]
data_long=data_long[-which(data_long$channel=="tv"),]
data_long=data_long[-which(data_long$channel=="session continuation"),]
#check channel distribution
data_long %>% group_by(channel) %>%  summarise(count=n()) %>% arrange(desc(count))
#reassign some channel names
disp_inds=grep("display",data_long$channel)
data_long$channel[disp_inds]="display"
email_inds=grep("email",data_long$channel)
data_long$channel[email_inds]="email"
email_inds=grep("paid",data_long$channel)
data_long$channel[email_inds]="paid"
email_inds=grep("organic",data_long$channel)
data_long$channel[email_inds]="organic"
data_long=data_long %>% group_by(order_number,channel) %>%
summarise(revenue=max(revenue),session_count=sum(session_count))
data_long %>% group_by(channel) %>%  summarise(count=n()) %>% arrange(desc(count))
data_long %>% group_by(order_number) %>%  summarise(count=n()) %>% arrange(desc(count))
channel_levels=levels(as.factor(data_long$channel))
resampled_data_frame=data.frame()
for (channel in channel_levels){
ch_inds=which(data_long$channel==channel)
for (i in 1:round(30000/length(ch_inds))){
temp=data_long[ch_inds,]
temp$order_number=paste0(temp$order_number,i)
resampled_data_frame=rbind(resampled_data_frame,temp)
}
}
resampled_data_frame %>% group_by(channel) %>%  summarise(count=n(),revenue=mean(revenue)) %>% arrange(desc(count))
data_wide=resampled_data_frame %>%   spread(key=channel,value=session_count)
names(data_wide) <- sub(" ", ".", names(data_wide))
numeric_inds=sapply(data_wide,is.numeric)
data_wide[,numeric_inds]=apply(data_wide[,numeric_inds],2,function(x){
na_inds=which(is.na(x))
if (length(na_inds)>0){
x[na_inds]=0
} else {
x
}
x
})
data_wide=data_wide %>% group_by(order_number) %>% summarise(revenue=mean(revenue),
affiliates=sum(affiliates),direct=sum(direct),display=sum(display),email=sum(email),
organic=sum(organic),paid=sum(paid),referral=sum(referral))
data_wide$order_number=NULL
View(data_wide)
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
summary(row_sums)
sd(row_sums)
qplot(row_sums)
high_inds=which(row_sums> (mean(row_sums)+10*sd(row_sums)))
if (length(high_inds)) data_wide=data_wide[-high_inds,]
summary(data_wide$revenue)
sd(data_wide$revenue)
qplot(data_wide$revenue)
high_inds=which(data_wide$revenue> (mean(data_wide$revenue)+10*sd(data_wide$revenue)))
if (length(high_inds)) data_wide=data_wide[-high_inds,]
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
cor(row_sums,data_wide$revenue)
qplot(row_sums,data_wide$revenue)+geom_smooth()+theme_bw()+
xlab("Sessions")+ylab("Purchase Total (Dollars)")
channels_dummy=data_wide
channels_dummy[,2:8]=data.frame(apply(channels_dummy[,2:8],2,function(x){
pos_inds=which(x>0)
x[pos_inds]=1
x
})
)
channels_invert=data_wide
channels_invert[,2:8]=data.frame(apply(channels_invert[,2:8],2,function(x){
pos_inds=which(x>0)
x[pos_inds]=1/x[pos_inds]
x
})
)
corrplot(cor(data_wide[,1:8]))
corrplot(cor(channels_dummy))
corrplot(cor(channels_invert))
corrplot(cor(data_wide[,1:8]))+title("hat")
all_model_no_interaction=lm(revenue~.+0,data=data_wide)
summary(all_model_no_interaction)
round(coef(all_model_no_interaction)/sum(coef(all_model_no_interaction)),3)
all_model_no_interaction_dummy=lm(revenue~.+0,data=channels_dummy)
summary(all_model_no_interaction_dummy)
round(coef(all_model_no_interaction_dummy)/sum(coef(all_model_no_interaction_dummy)),3)
all_model_no_interaction_invert=lm(revenue~.+0,data=channels_invert)
summary(all_model_no_interaction_invert)
round(coef(all_model_no_interaction_invert)/sum(coef(all_model_no_interaction_invert)),3)
all_model_dummy=lm(revenue~.*.+0,data=channels_dummy)
summary(all_model_dummy)
stepwise_model=step(all_model_dummy,k=log(nrow(channels_dummy)))
summary(stepwise_model)
anova(stepwise_model,all_model_no_interaction_dummy, test="Chi")
round(coef(stepwise_model)[1:7]/sum(coef(stepwise_model)[1:7]),2)
round(coef(all_model_no_interaction_dummy)/sum(coef(all_model_no_interaction_dummy)),3)
round(coef(all_model_no_interaction_dummy)/sum(coef(all_model_no_interaction_dummy)),2)
round(coef(stepwise_model)[1:7]/sum(coef(stepwise_model)[1:7]),2)
plot(stepwise_model)
library(tidyr)
library(dplyr)
library(corrplot)
library(glmnet)
source("Ritani_log_analysis_DB_connection.R")
query=paste("
SELECT order_number, name AS channel, state,
max(total) AS revenue, count(*) as session_count
FROM (
SELECT channel_id, clickstream_id, session_id
FROM channel_touchpoints
) ct INNER JOIN (
SELECT id, name, has_attributed_revenue
FROM channels
) ch ON ct.channel_id=ch.id
INNER JOIN (
SELECT id, pre_purchase
FROM sessions
WHERE pre_purchase=1
) se ON ct.session_id=se.id
INNER JOIN (
SELECT id, order_number, total, state
FROM clickstreams
) cl ON ct.clickstream_id=cl.id
GROUP BY order_number, channel
HAVING state LIKE '%shipped%' OR state LIKE '%accepted%' OR state LIKE '%delivered%'
OR state LIKE '%store%' OR state LIKE '%charged%' OR state LIKE '%authorized%'
OR state LIKE '%shipped%'
")
data_long=tbl_df(dbGetQuery(con,query))
#ditching some data
data_long$state=NULL
data_long=data_long[-which(data_long$revenue==0),]
data_long=data_long[-which(data_long$channel=="unknown"),]
data_long=data_long[-which(data_long$channel=="tv"),]
data_long=data_long[-which(data_long$channel=="session continuation"),]
#check channel distribution
data_long %>% group_by(channel) %>%  summarise(count=n()) %>% arrange(desc(count))
#reassign some channel names
disp_inds=grep("display",data_long$channel)
data_long$channel[disp_inds]="display"
email_inds=grep("email",data_long$channel)
data_long$channel[email_inds]="email"
email_inds=grep("paid",data_long$channel)
data_long$channel[email_inds]="paid"
email_inds=grep("organic",data_long$channel)
data_long$channel[email_inds]="organic"
#combine displays and combine emails by order
data_long=data_long %>% group_by(order_number,channel) %>%
summarise(revenue=max(revenue),session_count=sum(session_count))
#recheck channel distribution with corrections
data_long %>% group_by(channel) %>%  summarise(count=n()) %>% arrange(desc(count))
data_long %>% group_by(order_number) %>%  summarise(count=n()) %>% arrange(desc(count))
#need to resample to adjust for class imbalance
#duplicating instead of resampling due to order_number spreading difficulties
channel_levels=levels(as.factor(data_long$channel))
resampled_data_frame=data.frame()
for (channel in channel_levels){
ch_inds=which(data_long$channel==channel)
for (i in 1:round(60000/length(ch_inds))){
temp=data_long[ch_inds,]
temp$order_number=paste0(temp$order_number,i)
resampled_data_frame=rbind(resampled_data_frame,temp)
}
}
#recheck channel distribution with resampling
resampled_data_frame %>% group_by(channel) %>%  summarise(count=n(),revenue=mean(revenue)) %>% arrange(desc(count))
# putting data in wide form
data_wide=resampled_data_frame %>%   spread(key=channel,value=session_count)
#fix column names
names(data_wide) <- sub(" ", ".", names(data_wide))
#setting all missings to 0
numeric_inds=sapply(data_wide,is.numeric)
data_wide[,numeric_inds]=apply(data_wide[,numeric_inds],2,function(x){
na_inds=which(is.na(x))
if (length(na_inds)>0){
x[na_inds]=0
} else {
x
}
x
})
#combining orders for total sessions by each channel
data_wide=data_wide %>% group_by(order_number) %>% summarise(revenue=mean(revenue),
affiliates=sum(affiliates),direct=sum(direct),display=sum(display),email=sum(email),
organic=sum(organic),paid=sum(paid),referral=sum(referral))
#order_number is irrelevant now
data_wide$order_number=NULL
##Sanity checks
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
summary(row_sums)
sd(row_sums)
qplot(row_sums)
#omitting outrageously high session counts
high_inds=which(row_sums> (mean(row_sums)+10*sd(row_sums)))
if (length(high_inds)) data_wide=data_wide[-high_inds,]
summary(data_wide$revenue)
sd(data_wide$revenue)
qplot(data_wide$revenue)
#omitting outrageously revenue
high_inds=which(data_wide$revenue> (mean(data_wide$revenue)+10*sd(data_wide$revenue)))
if (length(high_inds)) data_wide=data_wide[-high_inds,]
row_sums=apply(data_wide[,2:8],1,function(x){sum(x)})
#check for implict relationship between total sessions and total revenue
cor(row_sums,data_wide$revenue)
qplot(row_sums,data_wide$revenue)+geom_smooth()+theme_bw()+
xlab("Sessions")+ylab("Purchase Total (Dollars)")
#Dummify for tabulation
channels_dummy=data_wide
channels_dummy[,2:8]=data.frame(apply(channels_dummy[,2:8],2,function(x){
pos_inds=which(x>0)
x[pos_inds]=1
x
})
)
#Invert session counts assuming more sessions are better
channels_invert=data_wide
channels_invert[,2:8]=data.frame(apply(channels_invert[,2:8],2,function(x){
pos_inds=which(x>0)
x[pos_inds]=1/x[pos_inds]
x
})
)
all_model_no_interaction_dummy=lm(revenue~.+0,data=channels_dummy)
all_model_no_interaction=lm(revenue~.+0,data=data_wide)
summary(all_model_no_interaction)
round(coef(all_model_no_interaction)/sum(coef(all_model_no_interaction)),2)
all_model_no_interaction_dummy=lm(revenue~.+0,data=channels_dummy)
summary(all_model_no_interaction_dummy)
round(coef(all_model_no_interaction_dummy)/sum(coef(all_model_no_interaction_dummy)),2)
all_model_no_interaction_invert=lm(revenue~.+0,data=channels_invert)
summary(all_model_no_interaction_invert)
round(coef(all_model_no_interaction_invert)/sum(coef(all_model_no_interaction_invert)),2)
all_model_dummy=lm(revenue~.*.+0,data=channels_dummy)
summary(all_model_dummy)
stepwise_model=step(all_model_dummy,k=log(nrow(channels_dummy)))
summary(stepwise_model)
anova(stepwise_model,all_model_no_interaction_dummy, test="Chi")
round(coef(stepwise_model)[1:7]/sum(coef(stepwise_model)[1:7]),2)
library(tidyr)
library(dplyr)
library(openxlsx)
library(lubridate)
library(ggplot2)
library(gridExtra)
library(forecast)
library(stats)
library(pander)
library(TTR)
library(googlesheets)
source("report_functions.R")
load(file="channel_sessions_long.rda")
freq=52
# Pretending Comcast never happened
# comcast_switch_date="2015-05-04"
# adap_switch_date="2015-09-14"
# comcast_ind=which(channel_sessions_long$date>comcast_switch_date & channel_sessions_long$date<adap_switch_date)
# channel_sessions_long$tv.spend[comcast_ind]=0
# Train only through September
# train_end_date="2015-10-01"
# train_end_ind=which(channel_sessions_long$date>=train_end_date)
#
# channel_sessions_long$direct.net.home[train_end_ind]=NA
# channel_sessions_long$direct.home[train_end_ind]=NA
# channel_sessions_long$organic.net.home[train_end_ind]=NA
# channel_sessions_long$organic.home[train_end_ind]=NA
# channel_sessions_long$paid.brand[train_end_ind]=NA
## Organic Net Home Channel
var_name="organic.net.home"
study_var=channel_sessions_long[,which(names(channel_sessions_long)==var_name)][[1]]
na_inds=which(is.na(study_var))
tv=channel_sessions_long$tv.spend[-na_inds]
study_var=na.omit(study_var)
date=channel_sessions_long$date[-na_inds]
title_paste="Organic Net of Home"
###ARIMAX model with TV spend
tv_arima=arima_func(stepwise_model,study_var,tv,freq)
###Forecasts
channel_sessions_long=add_forecast_to_df(channel_sessions_long,tv_arima,var_name)
#renaming variables to be like this channel
channel_sessions_long=channel_sessions_long %>% rename(organic.net.home.forecast=forecast)
channel_sessions_long=channel_sessions_long %>% rename(organic.net.home.lift=tv_lift)
channel_sessions_long=channel_sessions_long %>% rename(organic.net.home.lift.low.bound=tv_lift_low_bound)
channel_sessions_long=channel_sessions_long %>% rename(organic.net.home.lift.upper.bound=tv_lift_upper_bound)
# Plots for sanity check
#  ggplot(channel_sessions_long)+
#    geom_line(aes(x=date,y=organic.net.home))+
#    geom_line(aes(x=date,y=organic.net.home.lift))
## Organic Home Channel
var_name="organic.home"
study_var=channel_sessions_long[,which(names(channel_sessions_long)==var_name)][[1]]
na_inds=which(is.na(study_var))
tv=channel_sessions_long$tv.spend[-na_inds]
study_var=na.omit(study_var)
date=channel_sessions_long$date[-na_inds]
title_paste="Organic Home"
###ARIMAX model with TV spend
tv_arima=arima_func(stepwise_model,study_var,tv,freq)
###Forecasts
channel_sessions_long=add_forecast_to_df(channel_sessions_long,tv_arima,var_name)
#renaming variables to be like this channel
channel_sessions_long=channel_sessions_long %>% rename(organic.home.forecast=forecast)
channel_sessions_long=channel_sessions_long %>% rename(organic.home.lift=tv_lift)
channel_sessions_long=channel_sessions_long %>% rename(organic.home.lift.low.bound=tv_lift_low_bound)
channel_sessions_long=channel_sessions_long %>% rename(organic.home.lift.upper.bound=tv_lift_upper_bound)
# Plots for sanity check
# ggplot(channel_sessions_long)+
#   geom_line(aes(x=date,y=organic.home))+
#   geom_line(aes(x=date,y=tv_lift))
## Direct Net Home Channel
var_name="direct.net.home"
study_var=channel_sessions_long[,which(names(channel_sessions_long)==var_name)][[1]]
na_inds=which(is.na(study_var))
tv=channel_sessions_long$tv.spend[-na_inds]
study_var=na.omit(study_var)
date=channel_sessions_long$date[-na_inds]
title_paste="Direct Net Home"
###ARIMAX model with TV spend
tv_arima=arima_func(stepwise_model,study_var,tv,freq)
###Forecasts
channel_sessions_long=add_forecast_to_df(channel_sessions_long,tv_arima,var_name)
#renaming variables to be like this channel
channel_sessions_long=channel_sessions_long %>% rename(direct.net.home.forecast=forecast)
channel_sessions_long=channel_sessions_long %>% rename(direct.net.home.lift=tv_lift)
channel_sessions_long=channel_sessions_long %>% rename(direct.net.home.lift.low.bound=tv_lift_low_bound)
channel_sessions_long=channel_sessions_long %>% rename(direct.net.home.lift.upper.bound=tv_lift_upper_bound)
# Plots for sanity check
# ggplot(channel_sessions_long)+
#   geom_line(aes(x=date,y=direct.net.home))+
#   geom_line(aes(x=date,y=direct.net.home.lift))
## Direct Home Channel
var_name="direct.home"
study_var=channel_sessions_long[,which(names(channel_sessions_long)==var_name)][[1]]
na_inds=which(is.na(study_var))
tv=channel_sessions_long$tv.spend[-na_inds]
study_var=na.omit(study_var)
date=channel_sessions_long$date[-na_inds]
title_paste="Direct Home"
###ARIMAX model with TV spend
tv_arima=arima_func(stepwise_model,study_var,tv,freq)
###Forecasts
channel_sessions_long=add_forecast_to_df(channel_sessions_long,tv_arima,var_name)
#renaming variables to be like this channel
channel_sessions_long=channel_sessions_long %>% rename(direct.home.forecast=forecast)
channel_sessions_long=channel_sessions_long %>% rename(direct.home.lift=tv_lift)
channel_sessions_long=channel_sessions_long %>% rename(direct.home.lift.low.bound=tv_lift_low_bound)
channel_sessions_long=channel_sessions_long %>% rename(direct.home.lift.upper.bound=tv_lift_upper_bound)
# Plots for sanity check
# ggplot(channel_sessions_long)+
#   geom_line(aes(x=date,y=direct.home))+
#   geom_line(aes(x=date,y=direct.home.lift))
## Paid Brand Channel
var_name="paid.brand"
study_var=channel_sessions_long[,which(names(channel_sessions_long)==var_name)][[1]]
na_inds=which(is.na(study_var))
tv=channel_sessions_long$tv.spend[-na_inds]
study_var=na.omit(study_var)
date=channel_sessions_long$date[-na_inds]
title_paste="Paid Brand"
###ARIMAX model with TV spend
tv_arima=arima_func(stepwise_model,study_var,tv,freq)
###Forecasts
channel_sessions_long=add_forecast_to_df(channel_sessions_long,tv_arima,var_name)
#renaming variables to be like this channel
channel_sessions_long=channel_sessions_long %>% rename(paid.brand.sessions.forecast=forecast)
channel_sessions_long=channel_sessions_long %>% rename(paid.brand.lift=tv_lift)
channel_sessions_long=channel_sessions_long %>% rename(paid.brand.lift.low.bound=tv_lift_low_bound)
channel_sessions_long=channel_sessions_long %>% rename(paid.brand.lift.upper.bound=tv_lift_upper_bound)
# Plots for sanity check
channel_sessions_long
names(channel_sessions_long)
